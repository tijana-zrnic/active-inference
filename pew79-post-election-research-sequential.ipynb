{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eea4f23e-73c3-4ba1-9039-d4c49a2ad14c",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f654d93-bdc1-4649-912c-9a2351ccdfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pyreadstat\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm, bernoulli\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "import matplotlib.patheffects as pe\n",
    "from utils import make_width_coverage_plot, make_budget_plot\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a266e021-9925-4e06-96d9-e17d4b786055",
   "metadata": {},
   "source": [
    "### Import Pew ATP Wave 79 dataset\n",
    "\n",
    "The dataset is available at: https://www.pewresearch.org/science/dataset/american-trends-panel-wave-79/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9697dafe-52a3-481b-8050-472e4b1cefa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, meta = pyreadstat.read_sav(\"pew/ATPW79.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a6d35-4e35-4340-8377-edd5ed3d1813",
   "metadata": {},
   "source": [
    "### Problem setup\n",
    "\n",
    "Specify estimand of interest (average approval of Biden's messaging or average approval of Trump's messaging) and compute ground-truth value of the estimand. Split data into labeled and unlabeled subsets. Specify range of budgets in fractional form $n_b/n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45518c0a-1d0e-419c-b865-01b22c52eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"ELECTBIDENMSSG_W79\" # can choose ELECTBIDENMSSG_W79 or ELECTTRUMPMSSG_W79 \n",
    "idx_keep = np.where(data[question] != 99)[0]\n",
    "Y_all = data[question].to_numpy()[idx_keep] < 2.5\n",
    "X_all = data[['F_PARTYSUM_FINAL', 'COVIDFOL_W79','COVIDTHREAT_a_W79','COVIDTHREAT_b_W79','COVIDTHREAT_c_W79', 'COVIDTHREAT_d_W79','COVIDMASK1_W79', 'COVID_SCI6E_W79', 'F_EDUCCAT', 'F_AGECAT']].to_numpy()[idx_keep]\n",
    "theta_true = np.mean(Y_all)\n",
    "X_train, X, y_train, Y = train_test_split(X_all, Y_all, train_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450305b-7fd6-43a7-84ec-402987dbe70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "budgets = np.linspace(0.15, 0.4, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d058bfe-9230-438d-8608-88d429da59ec",
   "metadata": {},
   "source": [
    "### Train XGBoost model\n",
    "\n",
    "Train XGBoost model on labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29caeeea-f1d2-4786-95d0-6ba50e462758",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "tree = xgb.train({'eta': 0.001, 'max_depth': 5, 'objective': 'reg:logistic'}, dtrain, 3000)\n",
    "Yhat = tree.predict(xgb.DMatrix(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30711ae7-3212-4258-b308-7c47e6779e00",
   "metadata": {},
   "source": [
    "### Main experiment\n",
    "\n",
    "Forms dataframe ```df``` with experiment results. The columns in the dataframe are:\n",
    "\n",
    "- ```lb``` - interval lower bound\n",
    "\n",
    "- ```ub``` - interval upper bound\n",
    "\n",
    "- ```interval width``` - equal to ```ub``` - ```lb```\n",
    "\n",
    "- ```coverage``` - 0/1 indicator of whether or not interval covered target\n",
    "\n",
    "- ```estimator``` - one of ```active (w/ fine-tuning)```, ```uniform```, or ```active (no fine-tuning)```\n",
    "\n",
    "- ```$n_b$``` - budget size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56344b35-6ca6-4bf7-820c-c304c0608f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(Y)\n",
    "num_trials = 100\n",
    "alpha = 0.1\n",
    "tau = 0.5\n",
    "\n",
    "# fine-tuning params\n",
    "batch_size = 100\n",
    "steps = 500\n",
    "greedy_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b4742-2b91-47e6-8886-61310902bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "columns = [\"lb\", \"ub\", \"interval width\", \"coverage\", \"estimator\", \"$n_b$\"]\n",
    "temp_df = pd.DataFrame(np.zeros((3,len(columns))), columns=columns)\n",
    "Yhat_train = tree.predict(xgb.DMatrix(X_train))\n",
    "C_init = np.mean(np.minimum(Yhat_train, 1-Yhat_train))\n",
    "C = C_init\n",
    "\n",
    "for j in tqdm(range(len(budgets))):\n",
    "    budget = budgets[j]\n",
    "    budget_window = int(greedy_steps/budget) # how often we use up remaing budget\n",
    "\n",
    "    for k in tqdm(range(num_trials)):\n",
    "\n",
    "        perm = np.random.choice(range(n), n, replace=False)\n",
    "        Y = Y[perm]\n",
    "        Yhat = Yhat[perm]\n",
    "        X = X[perm]\n",
    "\n",
    "        increments_active = []\n",
    "        increments_nofinetune = []\n",
    "        tree_new = tree.copy()\n",
    "        finetune_inds = []\n",
    "        Yhat_new = tree_new.predict(xgb.DMatrix(X))\n",
    "        num_collected_active = 0\n",
    "        num_collected_nofinetune = 0\n",
    "        \n",
    "        for i in range(n):\n",
    "            raw_prob = np.clip(np.minimum(Yhat_new[i], 1-Yhat_new[i]) / C * budget, 0, np.maximum(0,(i+1)*budget - num_collected_active))\n",
    "            if i % budget_window >= budget_window - greedy_steps:\n",
    "                raw_prob = (i+1)*budget - num_collected_active\n",
    "            prob = (1-tau)*np.clip(raw_prob, 0, 1) + tau*budget\n",
    "            xi = bernoulli.rvs(prob)\n",
    "            if xi == 1:\n",
    "                finetune_inds.append(i)\n",
    "                num_collected_active +=1\n",
    "            increments_active.append(Yhat_new[i] + (Y[i] - Yhat_new[i])*xi/prob)\n",
    "            \n",
    "            if len(finetune_inds) == batch_size:\n",
    "                finetune_data = xgb.DMatrix(X[finetune_inds], label=Y[finetune_inds])\n",
    "                tree_new = xgb.train({'eta': 0.001, 'max_depth': 5, 'objective': 'reg:logistic'}, finetune_data, steps, xgb_model=tree_new)\n",
    "                Yhat_new = tree_new.predict(xgb.DMatrix(X))\n",
    "                Yhat_C = tree_new.predict(xgb.DMatrix(X[:(i+1)]))\n",
    "                C = np.mean(np.minimum(Yhat_C, 1-Yhat_C))\n",
    "                finetune_inds = []\n",
    "            \n",
    "            raw_prob_nofinetune = np.clip(np.minimum(Yhat[i], 1-Yhat[i]) / C_init * budget, 0, np.maximum(0,(i+1)*budget - num_collected_nofinetune))\n",
    "            if i % budget_window >= budget_window - greedy_steps:\n",
    "                raw_prob_nofinetune = (i+1)*budget - num_collected_nofinetune\n",
    "            prob_nofinetune = (1-tau)*np.clip(raw_prob_nofinetune, 0, 1) + tau*budget\n",
    "\n",
    "            # couple sampling decisions to minimize variance in results\n",
    "            if prob_nofinetune > prob:\n",
    "                if xi == 1:\n",
    "                    xi_nofinetune = 1\n",
    "                else:\n",
    "                    xi_nofinetune = bernoulli.rvs((prob_nofinetune - prob)/(1-prob))\n",
    "            else:\n",
    "                if xi == 0:\n",
    "                    xi_nofinetune = 0\n",
    "                else:\n",
    "                    xi_nofinetune = bernoulli.rvs(prob_nofinetune/prob)\n",
    "            if xi_nofinetune == 1:\n",
    "                num_collected_nofinetune += 1\n",
    "                \n",
    "            increments_nofinetune.append(Yhat[i] + (Y[i] - Yhat[i])*xi_nofinetune/prob_nofinetune)\n",
    "        \n",
    "        pointest_active = np.mean(increments_active)\n",
    "        pointest_active_std = np.std(increments_active) / np.sqrt(n)\n",
    "        pointest_nofinetune = np.mean(increments_nofinetune)\n",
    "        pointest_nofinetune_std = np.std(increments_nofinetune) / np.sqrt(n)\n",
    "            \n",
    "        width_active = norm.ppf(1-alpha/2)*pointest_active_std \n",
    "        coverage_active = (theta_true >= pointest_active - width_active)*(theta_true <= pointest_active + width_active)   \n",
    "        temp_df.loc[0] = pointest_active - width_active, pointest_active + width_active, 2*width_active, coverage_active, \"active (w/ fine-tuning)\", int(budget*n)\n",
    "\n",
    "        xi_unif = bernoulli.rvs([budget]*n)\n",
    "        pointest_unif = np.mean(Yhat + (Y - Yhat)*xi_unif/budget)\n",
    "        pointest_unif_std = np.std(Yhat + (Y - Yhat)*xi_unif/budget)/np.sqrt(n)\n",
    "        width_unif = norm.ppf(1-alpha/2)*pointest_unif_std\n",
    "        coverage_unif = (theta_true >= pointest_unif - width_unif)*(theta_true <= pointest_unif + width_unif)\n",
    "        temp_df.loc[1] = pointest_unif - width_unif, pointest_unif + width_unif, 2*width_unif, coverage_unif, \"uniform\", int(budget*n)\n",
    "        \n",
    "        width_nofinetune = norm.ppf(1-alpha/2)*pointest_nofinetune_std \n",
    "        coverage_nofinetune = (theta_true >= pointest_nofinetune - width_nofinetune)*(theta_true <= pointest_nofinetune + width_nofinetune)   \n",
    "        temp_df.loc[2] = pointest_nofinetune - width_nofinetune, pointest_nofinetune + width_nofinetune, 2*width_nofinetune, coverage_nofinetune, \"active (no fine-tuning)\", int(budget*n)\n",
    "\n",
    "        results += [temp_df.copy()]\n",
    "df = pd.concat(results,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626a1d68-2f65-4a97-89e9-9403c1a6d6aa",
   "metadata": {},
   "source": [
    "### Plot coverage and interval width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bec174-75d1-47f8-b99f-ced480443f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_width_coverage_plot(df, \"approval rate\", \"widths_and_coverage_pew79_biden_seq.pdf\", theta_true, num_trials=num_trials, n_example_ind=3, finetuning=True, more_precision=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7294175-e6da-44ca-a737-fe92dee86266",
   "metadata": {},
   "source": [
    "### Plot budget saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba1456-e1ad-4af6-b4e0-9d7251a32e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_budget_plot(df, \"Post-election survey research (Biden)\", \"budget_pew79_biden_seq.pdf\", finetuning=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
